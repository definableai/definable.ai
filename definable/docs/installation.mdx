---
title: Installation
description: Install Definable and configure your environment.
icon: download
---

## Requirements

- Python **3.12** or higher
- An API key from at least one supported LLM provider

## Install

<CodeGroup>
```bash pip
pip install definable-ai
```

```bash uv
uv add definable-ai
```

```bash From source
git clone https://github.com/definable-ai/definable.git
cd definable
pip install -e .
```
</CodeGroup>

## Core Dependencies

Definable installs these automatically:

| Package | Purpose |
|---------|---------|
| `openai` | OpenAI API client (also used by OpenAI-compatible providers) |
| `pydantic` | Data validation and structured outputs |
| `httpx` | HTTP client for async requests |
| `tiktoken` | Token counting |
| `rich` | Formatted logging and output |
| `docstring-parser` | Tool description extraction |
| `aiosqlite` | SQLite async driver for memory and identity resolution |

## Optional Dependencies

Some features require additional packages:

| Feature | Package(s) | Install |
|---------|------------|---------|
| PDF reading (knowledge) | `pypdf` | `pip install pypdf` |
| URL reading | `beautifulsoup4` | `pip install beautifulsoup4` |
| Voyage AI embeddings | `voyageai` | `pip install voyageai` |
| Cohere reranking | `cohere` | `pip install cohere` |
| PgVector database | `psycopg[binary]`, `pgvector` | `pip install psycopg[binary] pgvector` |
| Discord interface | `discord.py>=2.3.0` | `pip install 'definable-ai[discord]'` |
| All interfaces | `discord.py>=2.3.0` | `pip install 'definable-ai[interfaces]'` |
| File readers (PDF, DOCX, PPTX, XLSX, ODS, RTF) | `pypdf`, `python-docx`, `python-pptx`, `openpyxl`, `odfpy`, `striprtf` | `pip install 'definable-ai[readers]'` |
| PostgreSQL memory | `asyncpg>=0.29.0` | `pip install 'definable-ai[postgres-memory]'` |
| Redis memory | `redis>=5.0.0` | `pip install 'definable-ai[redis-memory]'` |
| Qdrant memory | `qdrant-client>=1.9.0` | `pip install 'definable-ai[qdrant-memory]'` |
| Chroma memory | `chromadb>=0.5.0` | `pip install 'definable-ai[chroma-memory]'` |
| MongoDB memory | `motor>=3.3.0` | `pip install 'definable-ai[mongodb-memory]'` |
| Pinecone memory | `pinecone>=5.0.0` | `pip install 'definable-ai[pinecone-memory]'` |
| Mistral OCR | `mistralai>=1.0.0` | `pip install 'definable-ai[mistral-ocr]'` |
| HTTP server | `fastapi`, `uvicorn` | `pip install 'definable-ai[serve]'` |
| Cron scheduling | `croniter` | `pip install 'definable-ai[cron]'` |
| JWT authentication | `pyjwt` | `pip install 'definable-ai[jwt]'` |
| Dev mode (hot-reload) | `watchfiles` | `pip install watchfiles` |
| Full runtime | All of the above | `pip install 'definable-ai[runtime]'` |

<Note>
The Signal interface has no pip dependency â€” it uses an external `signal-cli-rest-api` Docker container. See the [Signal interface docs](/interfaces/signal) for setup instructions.
</Note>

## Environment Variables

Set API keys as environment variables. Only the keys for providers you use are required.

```bash
# LLM Providers
export OPENAI_API_KEY="sk-..."
export DEEPSEEK_API_KEY="sk-..."
export MOONSHOT_API_KEY="sk-..."
export XAI_API_KEY="xai-..."

# Embedding Providers
export VOYAGE_API_KEY="pa-..."

# Reranking Providers
export COHERE_API_KEY="..."
```

<Tip>
You can also pass API keys directly when creating model instances:

```python
model = OpenAIChat(id="gpt-4o", api_key="sk-...")
```
</Tip>

## Verify Installation

```python
import definable
from definable.models import OpenAIChat

model = OpenAIChat(id="gpt-4o")
response = model.invoke(messages=[{"role": "user", "content": "Hello!"}])
print(response.content)
```

If you see a response, you are ready to go.

## Next Steps

<CardGroup cols={2}>
  <Card title="Quickstart" icon="bolt" href="/quickstart">
    Build your first model call, agent, and RAG query.
  </Card>
  <Card title="Models" icon="microchip" href="/models/overview">
    Explore all supported LLM providers.
  </Card>
</CardGroup>
