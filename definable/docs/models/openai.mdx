---
title: OpenAI
description: Use OpenAI models including GPT-4o, GPT-4o-mini, o1, and more.
icon: brain
---

## Setup

```bash
export OPENAI_API_KEY="sk-..."
```

## Basic Usage

```python
from definable.model.openai import OpenAIChat
from definable.model.message import Message

model = OpenAIChat(id="gpt-4o")
response = model.invoke(
    messages=[Message(role="user", content="Hello!")],
    assistant_message=Message(role="assistant", content=""),
)
print(response.content)
```

## Parameters

<ParamField path="id" type="str" default="gpt-4o">
  Model identifier. Common values: `gpt-4o`, `gpt-4o-mini`, `o1`, `o1-mini`, `o3-mini`.
</ParamField>

<ParamField path="api_key" type="str">
  OpenAI API key. Defaults to the `OPENAI_API_KEY` environment variable.
</ParamField>

<ParamField path="base_url" type="str">
  Override the API base URL.
</ParamField>

<ParamField path="temperature" type="float">
  Sampling temperature (0.0 to 2.0).
</ParamField>

<ParamField path="max_tokens" type="int">
  Maximum number of output tokens.
</ParamField>

<ParamField path="top_p" type="float">
  Nucleus sampling parameter.
</ParamField>

<ParamField path="frequency_penalty" type="float">
  Frequency penalty (-2.0 to 2.0).
</ParamField>

<ParamField path="presence_penalty" type="float">
  Presence penalty (-2.0 to 2.0).
</ParamField>

<ParamField path="seed" type="int">
  Seed for deterministic sampling.
</ParamField>

<ParamField path="strict_output" type="bool" default="true">
  Whether to use strict mode for structured outputs.
</ParamField>

## Structured Output

OpenAI supports native structured outputs via JSON Schema:

```python
import json
from pydantic import BaseModel
from definable.model.message import Message

class Movie(BaseModel):
    title: str
    year: int
    genre: str

response = model.invoke(
    messages=[Message(role="user", content="Recommend a sci-fi movie.")],
    assistant_message=Message(role="assistant", content=""),
    response_format=Movie,
)
movie = Movie(**json.loads(response.content))
print(movie)  # Movie(title='Interstellar', year=2014, genre='Science Fiction')
```

## Audio Support

OpenAI models support audio input and output:

```python
from definable.model.openai import OpenAIChat
from definable.model.message import Message

model = OpenAIChat(
    id="gpt-4o-audio-preview",
    modalities=["text", "audio"],
    audio={"voice": "alloy", "format": "wav"},
)

response = model.invoke(
    messages=[Message(role="user", content="Say hello in French.")],
    assistant_message=Message(role="assistant", content=""),
)
print(response.audio.transcript)
```

## Vision

Pass images in messages for visual understanding:

```python
from definable.media import Image
from definable.model.message import Message

response = model.invoke(
    messages=[Message(role="user", content="What's in this image?", images=[Image(url="https://example.com/photo.jpg")])],
    assistant_message=Message(role="assistant", content=""),
)
print(response.content)
```

## Async Usage

```python
from definable.model.message import Message

response = await model.ainvoke(
    messages=[Message(role="user", content="Hello!")],
    assistant_message=Message(role="assistant", content=""),
)
```

## Streaming

```python
from definable.model.message import Message

for chunk in model.invoke_stream(
    messages=[Message(role="user", content="Tell me a story.")],
    assistant_message=Message(role="assistant", content=""),
):
    if chunk.content:
        print(chunk.content, end="", flush=True)
```
